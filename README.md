## windows Pe malware detection using Ensamble learning

<h1>Introduction</h1>

- Malware detection is the process of ascertaining the presence of malware on a system or determining whether a program is malicious or harmless so that the system can be protected or recovered from any effects caused by the malicious code .<br>
- As the number of legitimate users of the Internet increases, so do the opportunities for cybercriminals to gain from manufacturing malware.<br>
- This is the reason that prompted the authors of the [article](https://www.mdpi.com/2227-9709/8/1/10) we investigated to develop a model for predicting whether a PE file is malicious or benign by methods of deep 
  learning and group learning.<br>
- We implemented the idea in the models and tried to slightly improve the results, which we did manage to do eventually.<br>
- We used the [dataset](https://www.kaggle.com/datasets/amauricio/pe-files-malwares/data) of the research from Kaggle.<br>
-  The data contains 19611 rows, and 79 columns <br>

<h2>Dimensionality Reduction </h2>

  - Following the research work - we used PCA to reduce the number of columns to 55, as determined by the researchers.
  - Before that, we carried out our own research and found that in advance we could not refer to 4 columns ('Name', 'Machine’, 'TimeDateStamp', and the target label 'Malware’ that mustn’t be reduced) that represent general or not significant information so that it does not constitute an impact on the data

<h2> Malware Detection Using Machine Learning</h2>
We used 5 ML models to detect the malware PE files:<br>
	- Gaussian Naïve Bayes,<br>
	- Decision Tree,<br>
	- Random Forest, <br>
	- AdaBoost, <br>
	- Gradient Boosting<be> 


![Screenshot 2024-04-11 121605](https://github.com/ohadtaizi/Microsoft-PE-malware-detection/assets/74296478/3e933405-46ce-4545-9c53-24448b4a9c29)

<h2>Deep learning models</h2>
- The next stage was implementing 3 DL models:
	1. MLP with 1 hidden layer
	2. MLP with 2 hidden layers
	3. 1D CNN

<h2>Malware Detection Using Deep Learning Models and Ensemble Learning</h2>
In the last stage they implemented an ensemble learning model by implementing the previous 3 dl models as the first stage, and on top of these results – machine learning models were implemented as the final stage.
<h2>The results we reached </h2>


| Metalearner |     our  | their |
|:-----|:--------:|------:|
| Decision Tree  |  0.99981 | 0.989 |
|Random Forest  |  0.99981  |   0.9924 |
| Extra Trees  | 0.99981 |    1 |
| KNN   |0.98266 |   0.979|
| LDA   |  0.97705 |    0.98 |
| AdaBoost   |0.97673 |    0.982 |
| SVM   |0.97654 |    0.982 |
| Logistic   |0.97642 |    0.981 |
| SGD   | 0.97508 |    0.979 |
| Passive   |0.97444 |    0.978|
| Gaussian   | 0.97291 |    0.972 |
| QDA   | 0.96577 |    0.973 |
